{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "data_training = pandas.read_csv('T.csv') \n",
    "data_testing = pandas.read_csv('V.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = data_training['lev_pref1'].values\n",
    "L2 = data_training['lev_pref2'].values\n",
    "M1 = data_testing['lev_pref1'].values\n",
    "M2 = data_testing['lev_pref2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = L1 - L2\n",
    "M = M1 - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = data_training\n",
    "History_vote = []\n",
    "Rows1 = []\n",
    "Rows2 = []\n",
    "for i in range(len(df1)):\n",
    "    if df1['actual_vote'].values[i] == df1['actual_vote'].values[i]:\n",
    "        if df1['actual_vote'].values[i] != df1['Cit_pref1'].values[i] and df1['actual_vote'].values[i] != df1['party_voted_past'].values[i]:\n",
    "            History_vote.append(1)\n",
    "            Rows1.append(i)\n",
    "        else:\n",
    "            History_vote.append(0)\n",
    "            Rows2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Train_SET1 = []\n",
    "Test_SET1 = []\n",
    "for i in range(len(L)):\n",
    "    if L1[i]>=5 and L[i]>=4.5:\n",
    "        Train_SET1.append(i)\n",
    "for i in range(len(M)):\n",
    "    if M1[i]>4 and M[i]>3:\n",
    "        Test_SET1.append(i)\n",
    "import numpy as np\n",
    "x = set(list(np.arange(len(L))))\n",
    "Train_SET2 = x - set(Train_SET1) \n",
    "data_training_set2 = data_training.drop(data_training.index[Train_SET1])\n",
    "data_training_set1 = data_training.drop(data_training.index[list(Train_SET2)])\n",
    "#data_training_set2 = data_training.ix[Rows]\n",
    "#data_training_set2 = data_training.ix[Rows2]\n",
    "\n",
    "x = set(list(np.arange(len(M))))\n",
    "Test_SET2 = x - set(Test_SET1) \n",
    "data_testing_set2 = data_testing.drop(data_testing.index[Test_SET1])\n",
    "data_testing_set1 = data_testing.drop(data_testing.index[list(Test_SET2)])\n",
    "#data_testing_set1 = data_testing[data_testing.Outlayers != 1] \n",
    "#data_testing_set2 = data_testing[data_testing.Outlayers != -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21207"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10499"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_testing_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = data_training_set2\n",
    "History_vote = []\n",
    "Rows = []\n",
    "for i in range(len(df1)):\n",
    "    if df1['actual_vote'].values[i] != df1['Cit_pref1'].values[i] and df1['actual_vote'].values[i] != df1['party_voted_past'].values[i] and df1['actual_vote'].values[i] != df1['ZIP_pref1'].values[i] and df1['actual_vote'].values[i] != df1['ZIP_pref2'].values[i] and df1['actual_vote'].values[i] != df1['Cit_pref2'].values[i]:\n",
    "        History_vote.append(1)\n",
    "        Rows.append(i)\n",
    "    else:\n",
    "        History_vote.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3414"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(History_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = data_training_set2\n",
    "History_vote = []\n",
    "for i in range(len(df1)):\n",
    "    if df1['actual_vote'].values[i] != df1['Cit_pref1'].values[i] and df1['actual_vote'].values[i] != df1['party_voted_past'].values[i]:\n",
    "        if df1['actual_vote'].values[i] == df1['ZIP_pref1'].values[i]:\n",
    "             History_vote.append(1)\n",
    "        else:\n",
    "             History_vote.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(History_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60129"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_features_test= ['Ebony','Odyssey','Tokugawa','mvar32','mvar33','Cosmos','Centaur','city_change','ZIP_pref1','ZIP_pref2','mvar34','mvar35','mvar29','lev_pref1','lev_pref2','ZIP_lev_pref1','ZIP_lev_pref2','mvar27','mvar28','mvar31']\n",
    "Feature = data_testing_set1.columns[3:28]\n",
    "new_features_train= ['Ebony','Odyssey','Tokugawa','Cosmos','Centaur','mvar32','mvar33','city_change','ZIP_pref1','ZIP_pref2','mvar34','mvar35','mvar29','lev_pref1','lev_pref2','ZIP_lev_pref1','ZIP_lev_pref2','mvar27','mvar28','mvar31']\n",
    "new_features_test = new_features_test +  list(Feature)\n",
    "new_features_train = new_features_train + list(Feature)\n",
    "Y_SET1 = data_training_set1['actual_vote'].values\n",
    "Y_SET2 = data_training_set2['actual_vote'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MinMax = MinMaxScaler()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for df in [data_testing_set1,data_testing_set2,data_training_set1,data_training_set2]:\n",
    "            for i in Feature:\n",
    "                df[i] = df[i].astype(str)\n",
    "            df = df[new_features_train][:]\n",
    "            df['mvar27'] = df['mvar27'].apply(str)\n",
    "            #df['lev_pref1'] = MinMax.fit_transform(df['lev_pref1'].values)\n",
    "            #df['ZIP_lev_pref1'] = MinMax.fit_transform(df['ZIP_lev_pref1'].values)\n",
    "            #df['ZIP_lev_pref2'] = MinMax.fit_transform(df['ZIP_lev_pref2'].values)\n",
    "            #df['lev_pref2'] = MinMax.fit_transform(df['lev_pref2'].values)\n",
    "            df['mvar35'] = MinMax.fit_transform(df['mvar35'].values)\n",
    "            df['mvar34'] = MinMax.fit_transform(df['mvar34'].values)\n",
    "            df['mvar28'] = MinMax.fit_transform(df['mvar28'].values)\n",
    "            df['mvar31'] = MinMax.fit_transform(df['mvar31'].values)\n",
    "            df['mvar29'] = MinMax.fit_transform(df['mvar29'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ENCODING\n",
    "data_training_1 = data_training_set1[new_features_test][:]\n",
    "data_testing_1 = data_testing_set1[new_features_test][:]\n",
    "X_train = data_training_1.to_dict('records')\n",
    "X_test = data_testing_1.to_dict('records')\n",
    "X_tr = []\n",
    "X_te = []\n",
    "X_tr.extend(X_train)\n",
    "X_te.extend(X_test)\n",
    "X_total = X_tr + X_te\n",
    "#One Hot Encoding \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "enc = DictVectorizer(sparse = True)\n",
    "X_encoded_total =enc.fit_transform(X_total)\n",
    "X_encoded_train_set1 =X_encoded_total[:len(X_tr)]\n",
    "X_encoded_test_set1 =X_encoded_total[len(X_tr):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ENCODING\n",
    "data_training_2 = data_training_set2[new_features_test][:]\n",
    "data_testing_2 = data_testing_set2[new_features_test][:]\n",
    "X_train = data_training_2.to_dict('records')\n",
    "X_test = data_testing_2.to_dict('records')\n",
    "X_tr = []\n",
    "X_te = []\n",
    "X_tr.extend(X_train)\n",
    "X_te.extend(X_test)\n",
    "X_total = X_tr + X_te\n",
    "#One Hot Encoding \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "enc = DictVectorizer(sparse = True)\n",
    "X_encoded_total =enc.fit_transform(X_total)\n",
    "X_encoded_train_set2 =X_encoded_total[:len(X_tr)]\n",
    "X_encoded_test_set2 =X_encoded_total[len(X_tr):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "clf_SET1 =SVC() #LogisticRegression(solver = 'newton-cg',fit_intercept = False)\n",
    "clf_SET2 =SVC()  #LogisticRegression(solver = 'newton-cg',fit_intercept = False)\n",
    "clf_SET1.fit(X_encoded_train_set1,Y_SET1)\n",
    "clf_SET2.fit(X_encoded_train_set2,Y_SET2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sol_SET1 =clf_SET1.predict(X_encoded_test_set1.toarray())\n",
    "sol_SET2 =clf_SET2.predict(X_encoded_test_set2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_testing_set2['Predicted'] = sol_SET2\n",
    "data_testing_set1['Predicted'] = sol_SET1\n",
    "DF1 = data_testing_set1[['citizen_id','Predicted']]\n",
    "DF2 = data_testing_set2[['citizen_id','Predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frames = [DF1, DF2]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('Fi8.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = data_testing_set2\n",
    "History_vote = []\n",
    "Rows1 = []\n",
    "Rows2 = []\n",
    "for i in range(len(df1)):\n",
    "    if df1['Predicted'].values[i] == df1['Predicted'].values[i]:\n",
    "        if df1['Predicted'].values[i] == df1['Cit_pref1'].values[i]:\n",
    "            History_vote.append(1)\n",
    "            Rows1.append(i)\n",
    "        else:\n",
    "            History_vote.append(0)\n",
    "            Rows2.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
